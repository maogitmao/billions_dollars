#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨ä¿¡æ¯çˆ¬è™« - è·å–å…¬å‘Šã€æ–°é—»ã€è´¢åŠ¡æ•°æ®ç­‰è¯¦ç»†ä¿¡æ¯

æ•°æ®æºï¼š
- ä¸œæ–¹è´¢å¯Œç½‘ï¼ˆå…¬å‘Šã€æ–°é—»ã€è´¢åŠ¡æ•°æ®ï¼‰
- æ–°æµªè´¢ç»ï¼ˆå®æ—¶èµ„è®¯ï¼‰
- åŒèŠ±é¡ºï¼ˆç ”æŠ¥ï¼‰
"""

import requests
from datetime import datetime
import json
import re


class StockInfoCrawler:
    """è‚¡ç¥¨ä¿¡æ¯çˆ¬è™«"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Referer': 'http://www.eastmoney.com/'
        })
    
    def get_stock_info(self, stock_code):
        """
        è·å–è‚¡ç¥¨çš„æ‰€æœ‰è¯¦ç»†ä¿¡æ¯
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            
        Returns:
            dict: åŒ…å«å…¬å‘Šã€æ–°é—»ã€è´¢åŠ¡ç­‰è¯¦ç»†ä¿¡æ¯
        """
        result = {
            'code': stock_code,
            'announcements': [],
            'news': [],
            'financial': {},
            'company_info': {},
            'research_reports': [],
            'capital_flow': {},
            'holder_info': {},
            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # è·å–å…¬å¸åŸºæœ¬ä¿¡æ¯
        try:
            company_info = self.get_company_info(stock_code)
            result['company_info'] = company_info
        except Exception as e:
            result['company_info_error'] = str(e)
        
        # è·å–å…¬å‘Šï¼ˆè¯¦ç»†ç‰ˆï¼‰
        try:
            announcements = self.get_announcements_detailed(stock_code)
            result['announcements'] = announcements
        except Exception as e:
            result['announcements_error'] = str(e)
        
        # è·å–æ–°é—»ï¼ˆè¯¦ç»†ç‰ˆï¼‰
        try:
            news = self.get_news_detailed(stock_code)
            result['news'] = news
        except Exception as e:
            result['news_error'] = str(e)
        
        # è·å–è´¢åŠ¡æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
        try:
            financial = self.get_financial_data_enhanced(stock_code)
            result['financial'] = financial
        except Exception as e:
            result['financial_error'] = str(e)
        
        # è·å–ç ”æŠ¥ä¿¡æ¯
        try:
            research = self.get_research_reports(stock_code)
            result['research_reports'] = research
        except Exception as e:
            result['research_error'] = str(e)
        
        # è·å–èµ„é‡‘æµå‘
        try:
            capital_flow = self.get_capital_flow(stock_code)
            result['capital_flow'] = capital_flow
        except Exception as e:
            result['capital_flow_error'] = str(e)
        
        # è·å–è‚¡ä¸œä¿¡æ¯
        try:
            holder_info = self.get_holder_info(stock_code)
            result['holder_info'] = holder_info
        except Exception as e:
            result['holder_error'] = str(e)
        
        # è·å–é¾™è™æ¦œæ•°æ®
        try:
            dragon_tiger = self.get_dragon_tiger_list(stock_code)
            result['dragon_tiger'] = dragon_tiger
        except Exception as e:
            result['dragon_tiger_error'] = str(e)
        
        return result
    
    def get_company_info(self, stock_code):
        """è·å–å…¬å¸åŸºæœ¬ä¿¡æ¯ï¼ˆå¢å¼ºç‰ˆï¼‰"""
        info = {}
        
        try:
            # åˆ¤æ–­å¸‚åœº
            if stock_code.startswith('6'):
                market_code = f'1.{stock_code}'
                market = 'sh'
            else:
                market_code = f'0.{stock_code}'
                market = 'sz'
            
            # ä¸œæ–¹è´¢å¯Œå…¬å¸ä¿¡æ¯æ¥å£
            url = 'http://push2.eastmoney.com/api/qt/stock/get'
            params = {
                'secid': market_code,
                'fields': 'f57,f58,f84,f85,f86,f127,f116,f117'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('data'):
                d = data['data']
                info['name'] = d.get('f58', '')
                info['high'] = d.get('f84', 0) / 100 if d.get('f84') else 0
                info['low'] = d.get('f85', 0) / 100 if d.get('f85') else 0
                info['volume'] = d.get('f86', 0)
                info['turnover_rate'] = d.get('f127', 0) / 100 if d.get('f127') else 0
            
            # è·å–å…¬å¸è¯¦ç»†ä¿¡æ¯ï¼ˆè¡Œä¸šã€ä¸»è¥ä¸šåŠ¡ç­‰ï¼‰
            try:
                detail_url = f'http://emweb.securities.eastmoney.com/PC_HSF10/CompanySurvey/Index'
                detail_params = {
                    'type': 'web',
                    'code': f'{market}{stock_code}'
                }
                detail_response = self.session.get(detail_url, params=detail_params, timeout=10)
                
                # å°è¯•ä»HTMLä¸­æå–ä¿¡æ¯
                import re
                html = detail_response.text
                
                # æå–è¡Œä¸š
                industry_match = re.search(r'æ‰€å±è¡Œä¸š[ï¼š:]\s*([^<\n]+)', html)
                if industry_match:
                    info['industry'] = industry_match.group(1).strip()
                else:
                    info['industry'] = 'æš‚æ— æ•°æ®'
                
                # æå–ä¸»è¥ä¸šåŠ¡
                business_match = re.search(r'ä¸»è¥ä¸šåŠ¡[ï¼š:]\s*([^<\n]{10,200})', html)
                if business_match:
                    info['main_business'] = business_match.group(1).strip()[:100]
                else:
                    info['main_business'] = 'æš‚æ— æ•°æ®'
                
                # æå–ä¸Šå¸‚æ—¥æœŸ
                listing_match = re.search(r'ä¸Šå¸‚æ—¶é—´[ï¼š:]\s*(\d{4}-\d{2}-\d{2})', html)
                if listing_match:
                    info['listing_date'] = listing_match.group(1)
                else:
                    info['listing_date'] = 'æš‚æ— æ•°æ®'
            
            except Exception as e:
                info['industry'] = 'æš‚æ— æ•°æ®'
                info['main_business'] = 'æš‚æ— æ•°æ®'
                info['listing_date'] = 'æš‚æ— æ•°æ®'
        
        except Exception as e:
            print(f"è·å–å…¬å¸ä¿¡æ¯å¤±è´¥: {e}")
        
        return info
    
    def get_announcements_detailed(self, stock_code, days=30, max_count=5):
        """
        è·å–è¯¦ç»†å…¬å‘Šä¿¡æ¯ï¼ˆä»ä¸œæ–¹è´¢å¯Œè‚¡å§å…¬å‘Šä¸“åŒºçˆ¬å–ï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            days: è·å–æœ€è¿‘å¤šå°‘å¤©çš„å…¬å‘Šï¼Œé»˜è®¤30å¤©ï¼ˆ1ä¸ªæœˆï¼‰
            max_count: æœ€å¤šè¿”å›å¤šå°‘æ¡å…¬å‘Šï¼Œé»˜è®¤5æ¡
        
        Returns:
            list: å…¬å‘Šåˆ—è¡¨
        """
        announcements = []
        
        try:
            from bs4 import BeautifulSoup
            import re
            from datetime import timedelta
            
            # è®¿é—®è‚¡å§å…¬å‘Šä¸“åŒºï¼ˆå‚æ•°3ä»£è¡¨å…¬å‘Šåˆ†ç±»ï¼‰
            url = f'http://guba.eastmoney.com/list,{stock_code},3,f.html'
            
            response = self.session.get(url, timeout=10)
            response.encoding = 'utf-8'  # ä½¿ç”¨UTF-8ç¼–ç 
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # æŸ¥æ‰¾å…¬å‘Šè¡¨æ ¼ä¸­çš„æ‰€æœ‰è¡Œ
                # è¡¨æ ¼ç»“æ„ï¼šé˜…è¯»æ•°ã€è¯„è®ºæ•°ã€æ ‡é¢˜ã€å…¬å‘Šç±»å‹ã€å…¬å‘Šæ—¥æœŸ
                rows = soup.find_all('tr')
                
                start_date = datetime.now() - timedelta(days=days)
                
                for row in rows:
                    try:
                        # æŸ¥æ‰¾æ‰€æœ‰å•å…ƒæ ¼
                        cells = row.find_all('td')
                        if len(cells) < 5:
                            continue
                        
                        # ç¬¬3åˆ—æ˜¯æ ‡é¢˜ï¼ˆç´¢å¼•2ï¼‰
                        title_cell = cells[2]
                        title_link = title_cell.find('a', href=re.compile(r'/news,'))
                        if not title_link:
                            continue
                        
                        title = title_link.get_text(strip=True)
                        href = title_link.get('href', '')
                        
                        # ç¬¬4åˆ—æ˜¯å…¬å‘Šç±»å‹ï¼ˆç´¢å¼•3ï¼‰
                        ann_type = cells[3].get_text(strip=True)
                        
                        # ç¬¬5åˆ—æ˜¯æ—¥æœŸï¼ˆç´¢å¼•4ï¼‰
                        date_text = cells[4].get_text(strip=True)
                        
                        # è§£ææ—¥æœŸï¼ˆæ ¼å¼ï¼š01-29 07:05 æˆ– 2025-01-29ï¼‰
                        date_str = ''
                        try:
                            # æå–æ—¥æœŸéƒ¨åˆ†ï¼ˆå»æ‰æ—¶é—´ï¼‰
                            date_part = date_text.split()[0] if ' ' in date_text else date_text
                            
                            if date_part.count('-') == 1:
                                # çŸ­æ—¥æœŸæ ¼å¼ï¼š01-29
                                current_year = datetime.now().year
                                current_month = datetime.now().month
                                month, day = date_part.split('-')
                                month_int = int(month)
                                
                                # å¦‚æœæœˆä»½å¤§äºå½“å‰æœˆä»½ï¼Œè¯´æ˜æ˜¯å»å¹´çš„
                                if month_int > current_month:
                                    year = current_year - 1
                                else:
                                    year = current_year
                                
                                date_str = f'{year}-{month.zfill(2)}-{day.zfill(2)}'
                                ann_date = datetime.strptime(date_str, '%Y-%m-%d')
                            elif date_part.count('-') == 2:
                                # å®Œæ•´æ—¥æœŸæ ¼å¼ï¼š2025-01-29
                                date_str = date_part
                                ann_date = datetime.strptime(date_str, '%Y-%m-%d')
                            else:
                                continue
                            
                            # æ£€æŸ¥æ˜¯å¦åœ¨æ—¶é—´èŒƒå›´å†…
                            if ann_date >= start_date:
                                # æ™ºèƒ½ç”Ÿæˆæ‘˜è¦
                                summary = self._generate_announcement_summary(title, ann_type)
                                
                                announcements.append({
                                    'title': title,
                                    'date': date_str,
                                    'type': ann_type if ann_type else 'å…¬å¸å…¬å‘Š',
                                    'url': f'http://guba.eastmoney.com{href}' if href.startswith('/') else href,
                                    'summary': summary
                                })
                                
                                # é™åˆ¶æœ€å¤šmax_countæ¡
                                if len(announcements) >= max_count:
                                    break
                        except Exception as date_error:
                            # æ—¥æœŸè§£æå¤±è´¥ï¼Œè·³è¿‡è¿™æ¡
                            continue
                    except Exception as row_error:
                        continue
            
            # å¦‚æœæ²¡æœ‰è·å–åˆ°å…¬å‘Šï¼Œæ·»åŠ è¯´æ˜
            if not announcements:
                stock_name = self._get_stock_name(stock_code)
                announcements.append({
                    'title': f'{stock_name}({stock_code}) - è¿‘{days}å¤©æ— å…¬å‘Š',
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'type': 'ç³»ç»Ÿæç¤º',
                    'url': '',
                    'summary': f'è¯¥è‚¡ç¥¨åœ¨æœ€è¿‘{days}å¤©å†…æ²¡æœ‰å‘å¸ƒå…¬å‘Šã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š1) å…¬å¸å¤„äºæ­£å¸¸ç»è¥çŠ¶æ€ï¼Œæ— é‡å¤§äº‹é¡¹éœ€æŠ«éœ²ï¼›2) éä¿¡æ¯æŠ«éœ²å¯†é›†æœŸï¼›3) å»ºè®®æŸ¥çœ‹æ›´æ—©æœŸçš„å…¬å‘Šæˆ–å…³æ³¨åç»­æ›´æ–°ã€‚'
                })
        
        except Exception as e:
            print(f"è·å–å…¬å‘Šå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            
            # æ·»åŠ è¯´æ˜
            stock_name = self._get_stock_name(stock_code)
            announcements.append({
                'title': f'{stock_name}({stock_code}) - è¿‘{days}å¤©æ— å…¬å‘Š',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'type': 'ç³»ç»Ÿæç¤º',
                'url': '',
                'summary': f'è¯¥è‚¡ç¥¨åœ¨æœ€è¿‘{days}å¤©å†…æ²¡æœ‰å‘å¸ƒå…¬å‘Šã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š1) å…¬å¸å¤„äºæ­£å¸¸ç»è¥çŠ¶æ€ï¼Œæ— é‡å¤§äº‹é¡¹éœ€æŠ«éœ²ï¼›2) éä¿¡æ¯æŠ«éœ²å¯†é›†æœŸï¼›3) å»ºè®®æŸ¥çœ‹æ›´æ—©æœŸçš„å…¬å‘Šæˆ–å…³æ³¨åç»­æ›´æ–°ã€‚'
            })
        
        return announcements
    
    def _get_announcements_backup(self, stock_code, days=7):
        """å¤‡ç”¨å…¬å‘Šè·å–æ¥å£"""
        announcements = []
        
        try:
            # åˆ¤æ–­å¸‚åœº
            if stock_code.startswith('6'):
                market = 'sh'
            else:
                market = 'sz'
            
            # è®¡ç®—èµ·å§‹æ—¥æœŸ
            from datetime import timedelta
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days)
            
            # ä½¿ç”¨æ—§ç‰ˆæ¥å£
            url = 'http://np-anotice-stock.eastmoney.com/api/security/ann'
            params = {
                'sr': -1,
                'page_size': 50,
                'page_index': 1,
                'ann_type': 'A',
                'client_source': 'web',
                'stock_list': f'{market}{stock_code}',
                'begin_time': start_date.strftime('%Y-%m-%d'),
                'end_time': end_date.strftime('%Y-%m-%d')
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('data') and data['data'].get('list'):
                for item in data['data']['list']:
                    notice_date = item.get('notice_date', '')
                    
                    try:
                        if notice_date:
                            ann_date = datetime.strptime(notice_date.split()[0], '%Y-%m-%d')
                            if ann_date >= start_date:
                                title = item.get('title', '')
                                ann_type = item.get('type_name', '')
                                
                                summary = self._generate_announcement_summary(title, ann_type)
                                
                                ann = {
                                    'title': title,
                                    'date': notice_date,
                                    'type': ann_type,
                                    'url': item.get('adjunct_url', ''),
                                    'summary': summary
                                }
                                
                                announcements.append(ann)
                                
                                if len(announcements) >= 20:
                                    break
                    except:
                        continue
        
        except Exception as e:
            print(f"å¤‡ç”¨æ¥å£è·å–å…¬å‘Šå¤±è´¥: {e}")
        
        return announcements
    
    def _generate_announcement_summary(self, title, ann_type):
        """æ™ºèƒ½ç”Ÿæˆå…¬å‘Šæ‘˜è¦"""
        # å…³é”®è¯æ˜ å°„
        keywords_map = {
            'ä¸šç»©': 'å…¬å¸å‘å¸ƒä¸šç»©ç›¸å…³å…¬å‘Šï¼Œæ¶‰åŠè´¢åŠ¡æ•°æ®å’Œç»è¥æƒ…å†µ',
            'è´¢æŠ¥': 'å…¬å¸å‘å¸ƒè´¢åŠ¡æŠ¥å‘Šï¼ŒæŠ«éœ²ç»è¥ä¸šç»©å’Œè´¢åŠ¡çŠ¶å†µ',
            'å¹´æŠ¥': 'å…¬å¸å‘å¸ƒå¹´åº¦æŠ¥å‘Šï¼Œå…¨é¢æŠ«éœ²å¹´åº¦ç»è¥æƒ…å†µ',
            'å­£æŠ¥': 'å…¬å¸å‘å¸ƒå­£åº¦æŠ¥å‘Šï¼ŒæŠ«éœ²å­£åº¦ç»è¥æ•°æ®',
            'åŠå¹´æŠ¥': 'å…¬å¸å‘å¸ƒåŠå¹´åº¦æŠ¥å‘Šï¼ŒæŠ«éœ²ä¸ŠåŠå¹´ç»è¥æƒ…å†µ',
            'åˆ†çº¢': 'å…¬å¸å‘å¸ƒåˆ†çº¢æ´¾æ¯æ–¹æ¡ˆï¼Œæ¶‰åŠè‚¡ä¸œåˆ©ç›Šåˆ†é…',
            'æ´¾æ¯': 'å…¬å¸å‘å¸ƒç°é‡‘åˆ†çº¢æ–¹æ¡ˆï¼Œå‘è‚¡ä¸œæ´¾å‘ç°é‡‘è‚¡åˆ©',
            'é€è‚¡': 'å…¬å¸å‘å¸ƒé€è‚¡æ–¹æ¡ˆï¼Œä»¥èµ„æœ¬å…¬ç§¯é‡‘è½¬å¢è‚¡æœ¬',
            'é…è‚¡': 'å…¬å¸å‘å¸ƒé…è‚¡æ–¹æ¡ˆï¼Œå‘ç°æœ‰è‚¡ä¸œé…å”®æ–°è‚¡',
            'é‡ç»„': 'å…¬å¸å‘å¸ƒé‡å¤§èµ„äº§é‡ç»„å…¬å‘Šï¼Œæ¶‰åŠèµ„äº§æ”¶è´­æˆ–å‡ºå”®',
            'å¹¶è´­': 'å…¬å¸å‘å¸ƒå¹¶è´­é‡ç»„å…¬å‘Šï¼Œæ¶‰åŠä¼ä¸šåˆå¹¶æˆ–æ”¶è´­',
            'å¢æŒ': 'è‚¡ä¸œå¢æŒå…¬å¸è‚¡ä»½ï¼Œæ˜¾ç¤ºå¯¹å…¬å¸ä¿¡å¿ƒ',
            'å‡æŒ': 'è‚¡ä¸œå‡æŒå…¬å¸è‚¡ä»½ï¼Œéœ€å…³æ³¨å‡æŒåŸå› å’Œè§„æ¨¡',
            'å›è´­': 'å…¬å¸å›è´­è‡ªèº«è‚¡ä»½ï¼Œé€šå¸¸ç”¨äºè‚¡æƒæ¿€åŠ±æˆ–å¸‚å€¼ç®¡ç†',
            'è‚¡æƒæ¿€åŠ±': 'å…¬å¸å®æ–½è‚¡æƒæ¿€åŠ±è®¡åˆ’ï¼Œæ¿€åŠ±ç®¡ç†å±‚å’Œæ ¸å¿ƒå‘˜å·¥',
            'å…³è”äº¤æ˜“': 'å…¬å¸ä¸å…³è”æ–¹å‘ç”Ÿäº¤æ˜“ï¼Œéœ€å…³æ³¨äº¤æ˜“å…¬å…æ€§',
            'è¯‰è®¼': 'å…¬å¸æ¶‰åŠæ³•å¾‹è¯‰è®¼ï¼Œå¯èƒ½å½±å“ç»è¥å’Œè´¢åŠ¡',
            'ä»²è£': 'å…¬å¸æ¶‰åŠä»²è£äº‹é¡¹ï¼Œéœ€å…³æ³¨ä»²è£ç»“æœ',
            'å¤„ç½š': 'å…¬å¸æˆ–ç›¸å…³äººå‘˜å—åˆ°ç›‘ç®¡å¤„ç½šï¼Œéœ€å…³æ³¨å½±å“',
            'é£é™©': 'å…¬å¸æç¤ºç»è¥é£é™©ï¼ŒæŠ•èµ„è€…éœ€è°¨æ…è¯„ä¼°',
            'æ¾„æ¸…': 'å…¬å¸æ¾„æ¸…å¸‚åœºä¼ é—»æˆ–ä¸å®ä¿¡æ¯',
            'æ›´æ­£': 'å…¬å¸æ›´æ­£æ­¤å‰å…¬å‘Šä¸­çš„é”™è¯¯ä¿¡æ¯',
            'è¡¥å……': 'å…¬å¸è¡¥å……æŠ«éœ²ç›¸å…³ä¿¡æ¯',
            'åœç‰Œ': 'å…¬å¸è‚¡ç¥¨åœç‰Œï¼Œé€šå¸¸å› é‡å¤§äº‹é¡¹',
            'å¤ç‰Œ': 'å…¬å¸è‚¡ç¥¨å¤ç‰Œï¼Œé‡å¤§äº‹é¡¹å·²æŠ«éœ²',
            'ä¸­æ ‡': 'å…¬å¸ä¸­æ ‡é¡¹ç›®ï¼Œå¯èƒ½å¢åŠ è¥ä¸šæ”¶å…¥',
            'åˆåŒ': 'å…¬å¸ç­¾è®¢é‡å¤§åˆåŒï¼Œæ¶‰åŠä¸šåŠ¡æ‹“å±•',
            'æŠ•èµ„': 'å…¬å¸å¯¹å¤–æŠ•èµ„ï¼Œæ‹“å±•ä¸šåŠ¡æˆ–è´¢åŠ¡æŠ•èµ„',
            'å‹Ÿèµ„': 'å…¬å¸å‹Ÿé›†èµ„é‡‘ï¼Œç”¨äºé¡¹ç›®å»ºè®¾æˆ–è¡¥å……æµåŠ¨èµ„é‡‘',
            'å€ºåˆ¸': 'å…¬å¸å‘è¡Œå€ºåˆ¸ï¼Œè¿›è¡Œå€ºåŠ¡èèµ„',
            'æ‹…ä¿': 'å…¬å¸æä¾›æ‹…ä¿ï¼Œéœ€å…³æ³¨æ‹…ä¿é£é™©',
            'å˜æ›´': 'å…¬å¸å‘ç”Ÿé‡è¦äº‹é¡¹å˜æ›´',
            'é€‰ä¸¾': 'å…¬å¸è‘£äº‹ä¼šæˆ–ç›‘äº‹ä¼šæ¢å±Šé€‰ä¸¾',
            'è¾èŒ': 'å…¬å¸é«˜ç®¡è¾èŒï¼Œéœ€å…³æ³¨åŸå› å’Œå½±å“',
            'ä»»å‘½': 'å…¬å¸ä»»å‘½æ–°çš„é«˜ç®¡äººå‘˜',
        }
        
        # æ ¹æ®æ ‡é¢˜å…³é”®è¯ç”Ÿæˆæ‘˜è¦
        for keyword, summary in keywords_map.items():
            if keyword in title:
                return summary
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°å…³é”®è¯ï¼Œä½¿ç”¨å…¬å‘Šç±»å‹
        if ann_type:
            return f'{ann_type}ç±»å…¬å‘Šï¼Œè¯¦è§å…¬å‘Šå…¨æ–‡'
        
        # é»˜è®¤æ‘˜è¦
        return 'å…¬å¸å‘å¸ƒå…¬å‘Šï¼Œè¯¦è§å…¬å‘Šå…¨æ–‡'
    
    def get_news_detailed(self, stock_code):
        """è·å–è¯¦ç»†æ–°é—»ä¿¡æ¯ï¼ˆåªè·å–ç›¸å…³æ–°é—»ï¼‰"""
        news = []
        
        try:
            # å…ˆè·å–è‚¡ç¥¨åç§°
            stock_name = self._get_stock_name(stock_code)
            
            # æ–¹æ³•1ï¼šä½¿ç”¨è‚¡ç¥¨ä»£ç æœç´¢
            url = 'http://search-api-web.eastmoney.com/search/jsonp'
            params = {
                'cb': 'jQuery',
                'param': json.dumps({
                    'uid': '',
                    'keyword': stock_code,
                    'type': ['cmsArticleWebOld'],
                    'client': 'web',
                    'clientType': 'web',
                    'clientVersion': '1.0',
                    'param': {
                        'cmsArticleWebOld': {
                            'searchScope': 'default',
                            'sort': 'default',
                            'pageIndex': 1,
                            'pageSize': 50  # è·å–æ›´å¤šï¼Œç„¶åç­›é€‰
                        }
                    }
                })
            }
            
            response = self.session.get(url, params=params, timeout=10)
            text = response.text
            
            # è§£æJSONP
            try:
                json_str = re.search(r'jQuery\((.*)\)', text).group(1)
                data = json.loads(json_str)
                
                if data.get('result') and data['result'].get('cmsArticleWebOld'):
                    articles = data['result']['cmsArticleWebOld']
                    
                    for article in articles:
                        title = article.get('title', '')
                        content = article.get('content', '')
                        
                        # æ¸…ç†HTMLæ ‡ç­¾
                        title_clean = re.sub(r'<[^>]+>', '', title)
                        content_clean = re.sub(r'<[^>]+>', '', content)
                        
                        # æ¸…ç†å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
                        title_clean = ' '.join(title_clean.split())
                        content_clean = ' '.join(content_clean.split())
                        
                        # ç­›é€‰ç›¸å…³æ–°é—»
                        is_relevant = False
                        
                        # æ’é™¤é¾™è™æ¦œç›¸å…³æ–°é—»ï¼ˆå› ä¸ºæœ‰ä¸“é—¨çš„é¾™è™æ¦œæ•°æ®ï¼‰
                        if 'é¾™è™æ¦œ' in title_clean:
                            continue
                        
                        # æ’é™¤é€šç”¨åˆ—è¡¨ç±»æ–°é—»ï¼ˆä¼˜å…ˆåˆ¤æ–­ï¼‰
                        exclude_patterns = [
                            r'\d+åª.*è‚¡',  # "73åªä¸ªè‚¡"
                            r'\d+å®¶å…¬å¸',  # "60å®¶å…¬å¸"
                            r'ä»Šæ—¥.*ä¸ªè‚¡',  # "ä»Šæ—¥48åªä¸ªè‚¡"
                            r'ç›˜ä¸­.*ä¸ªè‚¡',  # "ç›˜ä¸­çªç ´"
                            r'æ¦‚å¿µ.*æ¶¨',   # "å°é‡‘å±æ¦‚å¿µæ¶¨"
                            r'ä¸»åŠ›èµ„é‡‘å‡€æµå…¥\d+è‚¡',  # "ä¸»åŠ›èµ„é‡‘å‡€æµå…¥111è‚¡"
                        ]
                        
                        is_excluded = False
                        for pattern in exclude_patterns:
                            if re.search(pattern, title_clean):
                                is_excluded = True
                                break
                        
                        if is_excluded:
                            continue
                        
                        # 1. æ ‡é¢˜åŒ…å«è‚¡ç¥¨ä»£ç ä¸”ä¸æ˜¯åˆ—è¡¨ï¼ˆæœ€ç›¸å…³ï¼‰
                        if stock_code in title_clean:
                            # ç¡®ä¿ä¸æ˜¯ç®€å•æåŠï¼Œè€Œæ˜¯ä¸»é¢˜
                            if len(title_clean) > 10:  # æ ‡é¢˜è¶³å¤Ÿé•¿
                                is_relevant = True
                        # 2. æ ‡é¢˜åŒ…å«è‚¡ç¥¨åç§°ï¼ˆç›¸å…³ï¼‰
                        elif stock_name != stock_code and len(stock_name) > 2 and stock_name in title_clean:
                            # ç¡®ä¿ä¸æ˜¯åˆ—è¡¨ä¸­çš„ä¸€ä¸ª
                            if len(title_clean) < 50:  # æ ‡é¢˜ä¸å¤ªé•¿ï¼ˆåˆ—è¡¨æ ‡é¢˜é€šå¸¸å¾ˆé•¿ï¼‰
                                is_relevant = True
                        
                        if is_relevant:
                            # ç”Ÿæˆæœ‰æ„ä¹‰çš„æ‘˜è¦
                            if content_clean and len(content_clean) > 20:
                                # ä¼˜å…ˆæå–åŒ…å«è‚¡ç¥¨ä»£ç æˆ–åç§°çš„å¥å­
                                sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content_clean)
                                relevant_sentences = []
                                
                                for sentence in sentences:
                                    if stock_code in sentence or (stock_name != stock_code and stock_name in sentence):
                                        relevant_sentences.append(sentence.strip())
                                        if len('ã€‚'.join(relevant_sentences)) > 150:
                                            break
                                
                                if relevant_sentences:
                                    summary = 'ã€‚'.join(relevant_sentences)[:200]
                                    if not summary.endswith('ã€‚'):
                                        summary += '...'
                                else:
                                    # å¦‚æœæ²¡æœ‰ç›¸å…³å¥å­ï¼Œå–å¼€å¤´
                                    summary = content_clean[:200]
                                    if len(content_clean) > 200:
                                        summary += '...'
                            else:
                                summary = f"å…³äº{stock_name}({stock_code})çš„èµ„è®¯"
                            
                            news.append({
                                'title': title_clean,
                                'date': article.get('date', ''),
                                'source': article.get('mediaName', 'ä¸œæ–¹è´¢å¯Œ'),
                                'url': article.get('url', ''),
                                'summary': summary
                            })
                            
                            if len(news) >= 15:
                                break
            except Exception as e:
                print(f"è§£ææ–°é—»æ•°æ®å¤±è´¥: {e}")
            
            # å¦‚æœæ–°é—»å¤ªå°‘ï¼Œæ·»åŠ æç¤º
            if len(news) == 0:
                news.append({
                    'title': f'{stock_name}({stock_code}) - æš‚æ— æœ€æ–°ä¸“å±èµ„è®¯',
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'source': 'ç³»ç»Ÿæç¤º',
                    'url': '',
                    'summary': f'å½“å‰æš‚æ— ä¸“é—¨é’ˆå¯¹{stock_name}({stock_code})çš„æ–°é—»èµ„è®¯ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š1) è¯¥è‚¡ç¥¨è¿‘æœŸæ²¡æœ‰é‡å¤§æ–°é—»ï¼›2) å…¬å¸å¤„äºæ­£å¸¸ç»è¥çŠ¶æ€ï¼›3) å»ºè®®æŸ¥çœ‹å…¬å‘Šä¿¡æ¯äº†è§£å…¬å¸åŠ¨æ€ã€‚'
                })
            elif len(news) < 5:
                # æ–°é—»è¾ƒå°‘æ—¶æ·»åŠ è¯´æ˜
                news.append({
                    'title': f'{stock_name}({stock_code}) - æ–°é—»æ•°é‡è¯´æ˜',
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'source': 'ç³»ç»Ÿæç¤º',
                    'url': '',
                    'summary': f'å½“å‰ä»…è·å–åˆ°{len(news)}æ¡ä¸{stock_name}({stock_code})ç›´æ¥ç›¸å…³çš„æ–°é—»ã€‚è¿™æ˜¯æ­£å¸¸ç°è±¡ï¼Œè¯´æ˜è¯¥è‚¡ç¥¨è¿‘æœŸæ–°é—»æŠ¥é“è¾ƒå°‘ã€‚å»ºè®®å…³æ³¨å…¬å‘Šä¿¡æ¯è·å–æ›´å¤šå…¬å¸åŠ¨æ€ã€‚'
                })
        
        except Exception as e:
            print(f"è·å–æ–°é—»å¤±è´¥: {e}")
            # æ·»åŠ é”™è¯¯æç¤º
            news.append({
                'title': f'{stock_code} - æ–°é—»è·å–å¤±è´¥',
                'date': datetime.now().strftime('%Y-%m-%d'),
                'source': 'ç³»ç»Ÿæç¤º',
                'url': '',
                'summary': f'è·å–æ–°é—»æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}ã€‚è¯·ç¨åé‡è¯•æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚'
            })
        
        return news
    
    def _get_stock_name(self, stock_code):
        """è·å–è‚¡ç¥¨åç§°"""
        try:
            if stock_code.startswith('6'):
                market_code = f'1.{stock_code}'
            else:
                market_code = f'0.{stock_code}'
            
            url = 'http://push2.eastmoney.com/api/qt/stock/get'
            params = {
                'secid': market_code,
                'fields': 'f58'
            }
            
            response = self.session.get(url, params=params, timeout=5)
            data = response.json()
            
            if data.get('data'):
                return data['data'].get('f58', stock_code)
        except:
            pass
        
        return stock_code
    
    def get_financial_data_enhanced(self, stock_code):
        """è·å–å¢å¼ºç‰ˆè´¢åŠ¡æ•°æ®"""
        financial = {}
        
        try:
            # åˆ¤æ–­å¸‚åœº
            if stock_code.startswith('6'):
                market_code = f'1.{stock_code}'
            else:
                market_code = f'0.{stock_code}'
            
            # ä¸œæ–¹è´¢å¯Œè´¢åŠ¡æ•°æ®æ¥å£
            url = 'http://push2.eastmoney.com/api/qt/stock/get'
            params = {
                'secid': market_code,
                'fields': 'f57,f58,f116,f117,f162,f163,f164,f165,f166,f167,f168,f169,f170,f171'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('data'):
                d = data['data']
                financial['pe_ratio'] = d.get('f162', 0) / 100 if d.get('f162') else 0  # å¸‚ç›ˆç‡
                financial['pb_ratio'] = d.get('f167', 0) / 100 if d.get('f167') else 0  # å¸‚å‡€ç‡
                financial['roe'] = d.get('f164', 0) / 100 if d.get('f164') else 0  # ROE
                financial['total_market_cap'] = d.get('f116', 0) / 100000000 if d.get('f116') else 0  # æ€»å¸‚å€¼ï¼ˆäº¿ï¼‰
                financial['circulation_market_cap'] = d.get('f117', 0) / 100000000 if d.get('f117') else 0  # æµé€šå¸‚å€¼ï¼ˆäº¿ï¼‰
                financial['eps'] = d.get('f170', 0) / 100 if d.get('f170') else 0  # æ¯è‚¡æ”¶ç›Š
                financial['bvps'] = d.get('f171', 0) / 100 if d.get('f171') else 0  # æ¯è‚¡å‡€èµ„äº§
                
                # è®¡ç®—å¸‚é”€ç‡ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
                if d.get('f168'):
                    financial['ps_ratio'] = d.get('f168', 0) / 100
                
                # è®¡ç®—å¸‚ç°ç‡ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
                if d.get('f169'):
                    financial['pcf_ratio'] = d.get('f169', 0) / 100
        
        except Exception as e:
            print(f"è·å–è´¢åŠ¡æ•°æ®å¤±è´¥: {e}")
        
        return financial
    
    def get_research_reports(self, stock_code):
        """è·å–ç ”æŠ¥ä¿¡æ¯"""
        reports = []
        
        try:
            # åˆ¤æ–­å¸‚åœº
            if stock_code.startswith('6'):
                market = 'sh'
            else:
                market = 'sz'
            
            # ä¸œæ–¹è´¢å¯Œç ”æŠ¥æ¥å£
            url = 'http://reportapi.eastmoney.com/report/list'
            params = {
                'cb': 'datatable',
                'industryCode': '*',
                'pageSize': 10,
                'industry': '*',
                'rating': '*',
                'ratingChange': '*',
                'beginTime': '',
                'endTime': '',
                'pageNo': 1,
                'fields': '',
                'qType': 0,
                'orgCode': '',
                'code': f'{market}{stock_code}',
                '_': '1234567890'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            text = response.text
            
            # è§£æJSONP
            try:
                json_str = re.search(r'datatable\((.*)\)', text).group(1)
                data = json.loads(json_str)
                
                if data.get('data'):
                    for item in data['data'][:5]:  # å–å‰5æ¡
                        reports.append({
                            'title': item.get('title', ''),
                            'org': item.get('orgSName', ''),
                            'researcher': item.get('researcher', ''),
                            'rating': item.get('rating', ''),
                            'date': item.get('publishDate', ''),
                            'summary': item.get('title', '')[:100]
                        })
            except:
                pass
        
        except Exception as e:
            print(f"è·å–ç ”æŠ¥å¤±è´¥: {e}")
        
        return reports
    
    def get_capital_flow(self, stock_code):
        """è·å–èµ„é‡‘æµå‘"""
        flow = {}
        
        try:
            # åˆ¤æ–­å¸‚åœº
            if stock_code.startswith('6'):
                market_code = f'1.{stock_code}'
            else:
                market_code = f'0.{stock_code}'
            
            # ä¸œæ–¹è´¢å¯Œèµ„é‡‘æµå‘æ¥å£
            url = 'http://push2.eastmoney.com/api/qt/stock/fflow/kline/get'
            params = {
                'lmt': 1,
                'klt': 101,
                'secid': market_code,
                'fields1': 'f1,f2,f3,f7',
                'fields2': 'f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61,f62,f63,f64,f65'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('data') and data['data'].get('klines'):
                kline = data['data']['klines'][0].split(',')
                if len(kline) >= 7:
                    flow['main_net_inflow'] = float(kline[1]) / 10000  # ä¸»åŠ›å‡€æµå…¥ï¼ˆä¸‡å…ƒï¼‰
                    flow['small_net_inflow'] = float(kline[2]) / 10000  # å°å•å‡€æµå…¥ï¼ˆä¸‡å…ƒï¼‰
                    flow['medium_net_inflow'] = float(kline[3]) / 10000  # ä¸­å•å‡€æµå…¥ï¼ˆä¸‡å…ƒï¼‰
                    flow['large_net_inflow'] = float(kline[4]) / 10000  # å¤§å•å‡€æµå…¥ï¼ˆä¸‡å…ƒï¼‰
                    flow['super_net_inflow'] = float(kline[5]) / 10000  # è¶…å¤§å•å‡€æµå…¥ï¼ˆä¸‡å…ƒï¼‰
        
        except Exception as e:
            print(f"è·å–èµ„é‡‘æµå‘å¤±è´¥: {e}")
        
        return flow
    
    def get_holder_info(self, stock_code):
        """è·å–è‚¡ä¸œä¿¡æ¯"""
        holder = {}
        
        try:
            # åˆ¤æ–­å¸‚åœº
            if stock_code.startswith('6'):
                market = 'sh'
            else:
                market = 'sz'
            
            # ä¸œæ–¹è´¢å¯Œè‚¡ä¸œä¿¡æ¯æ¥å£
            url = 'http://emweb.securities.eastmoney.com/PC_HSF10/ShareholderResearch/Index'
            params = {
                'type': 'web',
                'code': f'{market}{stock_code}'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            html = response.text
            
            # æå–è‚¡ä¸œæˆ·æ•°
            holder_count_match = re.search(r'è‚¡ä¸œæˆ·æ•°[ï¼š:]\s*([0-9,]+)', html)
            if holder_count_match:
                holder['holder_count'] = holder_count_match.group(1)
            
            # æå–äººå‡æŒè‚¡
            avg_hold_match = re.search(r'äººå‡æŒè‚¡[ï¼š:]\s*([0-9,.]+)', html)
            if avg_hold_match:
                holder['avg_hold'] = avg_hold_match.group(1)
            
            # æå–å‰åå¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹
            top10_match = re.search(r'å‰åå¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹[ï¼š:]\s*([0-9.]+)%', html)
            if top10_match:
                holder['top10_ratio'] = float(top10_match.group(1))
        
        except Exception as e:
            print(f"è·å–è‚¡ä¸œä¿¡æ¯å¤±è´¥: {e}")
        
        return holder
    
    def get_dragon_tiger_list(self, stock_code, days=30):
        """
        è·å–é¾™è™æ¦œæ•°æ®ï¼ˆè¯¦ç»†ç‰ˆï¼‰
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            days: è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®ï¼Œé»˜è®¤30å¤©
            
        Returns:
            list: é¾™è™æ¦œè®°å½•åˆ—è¡¨
        """
        dragon_tiger_list = []
        
        try:
            # åˆ¤æ–­å¸‚åœº
            if stock_code.startswith('6'):
                market = 'SH'
            else:
                market = 'SZ'
            
            # ä¸œæ–¹è´¢å¯Œé¾™è™æ¦œæ¥å£
            url = 'http://datacenter-web.eastmoney.com/api/data/v1/get'
            params = {
                'sortColumns': 'TRADE_DATE,SECURITY_CODE',
                'sortTypes': '-1,-1',
                'pageSize': 50,
                'pageNumber': 1,
                'reportName': 'RPT_DAILYBILLBOARD_DETAILS',
                'columns': 'ALL',
                'filter': f'(SECURITY_CODE="{stock_code}")(TRADE_DATE>=\'{(datetime.now() - __import__("datetime").timedelta(days=days)).strftime("%Y-%m-%d")}\')'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            if data.get('result') and data['result'].get('data'):
                for item in data['result']['data']:
                    record = {
                        'date': item.get('TRADE_DATE', ''),
                        'reason': item.get('EXPLANATION', ''),  # ä¸Šæ¦œåŸå› 
                        'close_price': item.get('CLOSE_PRICE', 0),  # æ”¶ç›˜ä»·
                        'change_pct': item.get('CHANGE_RATE', 0),  # æ¶¨è·Œå¹…
                        'turnover': item.get('TURNOVER', 0) / 100000000,  # æˆäº¤é¢ï¼ˆäº¿ï¼‰
                        'net_amount': item.get('NET_AMT', 0) / 10000,  # å‡€ä¹°å…¥é¢ï¼ˆä¸‡ï¼‰
                        'buy_amount': item.get('BUY', 0) / 10000,  # ä¹°å…¥é¢ï¼ˆä¸‡ï¼‰
                        'sell_amount': item.get('SELL', 0) / 10000,  # å–å‡ºé¢ï¼ˆä¸‡ï¼‰
                        'total_amount': item.get('ACCUM_AMOUNT', 0) / 10000,  # æ€»æˆäº¤é¢ï¼ˆä¸‡ï¼‰
                        'details': []  # è¥ä¸šéƒ¨æ˜ç»†
                    }
                    
                    # è·å–è¯¥æ—¥æœŸçš„è¥ä¸šéƒ¨æ˜ç»†
                    trade_date = item.get('TRADE_DATE', '')
                    if trade_date:
                        details = self._get_dragon_tiger_details(stock_code, trade_date)
                        record['details'] = details
                    
                    dragon_tiger_list.append(record)
                    
                    # åªä¿ç•™æœ€è¿‘3æ¬¡
                    if len(dragon_tiger_list) >= 3:
                        break
            
            # å¦‚æœæ²¡æœ‰é¾™è™æ¦œæ•°æ®ï¼Œæ·»åŠ è¯´æ˜
            if not dragon_tiger_list:
                stock_name = self._get_stock_name(stock_code)
                dragon_tiger_list.append({
                    'date': datetime.now().strftime('%Y-%m-%d'),
                    'reason': f'{stock_name}({stock_code}) - è¿‘1ä¸ªæœˆæœªä¸Šé¾™è™æ¦œ',
                    'close_price': 0,
                    'change_pct': 0,
                    'turnover': 0,
                    'net_amount': 0,
                    'buy_amount': 0,
                    'sell_amount': 0,
                    'total_amount': 0,
                    'details': [],
                    'note': f'è¯¥è‚¡ç¥¨åœ¨æœ€è¿‘1ä¸ªæœˆå†…æœªç™»ä¸Šé¾™è™æ¦œã€‚é¾™è™æ¦œé€šå¸¸è®°å½•å¼‚å¸¸æ³¢åŠ¨ã€æ¶¨è·Œå¹…è¾ƒå¤§æˆ–æˆäº¤é‡å¼‚å¸¸çš„è‚¡ç¥¨ã€‚æœªä¸Šæ¦œè¯´æ˜è¯¥è‚¡ç¥¨äº¤æ˜“ç›¸å¯¹å¹³ç¨³ã€‚'
                })
        
        except Exception as e:
            print(f"è·å–é¾™è™æ¦œå¤±è´¥: {e}")
            dragon_tiger_list.append({
                'date': datetime.now().strftime('%Y-%m-%d'),
                'reason': f'{stock_code} - é¾™è™æ¦œæ•°æ®è·å–å¤±è´¥',
                'close_price': 0,
                'change_pct': 0,
                'turnover': 0,
                'net_amount': 0,
                'buy_amount': 0,
                'sell_amount': 0,
                'total_amount': 0,
                'details': [],
                'note': f'è·å–é¾™è™æ¦œæ•°æ®æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}ã€‚è¯·ç¨åé‡è¯•ã€‚'
            })
        
        return dragon_tiger_list
    
    def _get_dragon_tiger_details(self, stock_code, trade_date):
        """
        è·å–é¾™è™æ¦œè¥ä¸šéƒ¨æ˜ç»†
        
        Args:
            stock_code: è‚¡ç¥¨ä»£ç 
            trade_date: äº¤æ˜“æ—¥æœŸ
            
        Returns:
            list: è¥ä¸šéƒ¨ä¹°å–æ˜ç»†
        """
        details = []
        
        try:
            # ä¸œæ–¹è´¢å¯Œé¾™è™æ¦œæ˜ç»†æ¥å£
            url = 'http://datacenter-web.eastmoney.com/api/data/v1/get'
            params = {
                'sortColumns': 'TRADE_DATE,SECURITY_CODE',
                'sortTypes': '-1,-1',
                'pageSize': 20,
                'pageNumber': 1,
                'reportName': 'RPT_BILLBOARD_DAILYDETAILSBUY',  # ä¹°å…¥æ˜ç»†
                'columns': 'ALL',
                'filter': f'(SECURITY_CODE="{stock_code}")(TRADE_DATE=\'{trade_date}\')'
            }
            
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            # ä¹°å…¥è¥ä¸šéƒ¨
            buy_list = []
            if data.get('result') and data['result'].get('data'):
                for item in data['result']['data'][:5]:  # å‰5å¤§ä¹°å…¥
                    buy_list.append({
                        'type': 'ä¹°å…¥',
                        'name': item.get('OPERATEDEPT_NAME', ''),
                        'buy_amount': item.get('BUY', 0) / 10000,  # ä¸‡å…ƒ
                        'sell_amount': item.get('SELL', 0) / 10000,  # ä¸‡å…ƒ
                        'net_amount': item.get('NET', 0) / 10000  # å‡€ä¹°å…¥ï¼ˆä¸‡å…ƒï¼‰
                    })
            
            # å–å‡ºè¥ä¸šéƒ¨
            params['reportName'] = 'RPT_BILLBOARD_DAILYDETAILSSELL'
            response = self.session.get(url, params=params, timeout=10)
            data = response.json()
            
            sell_list = []
            if data.get('result') and data['result'].get('data'):
                for item in data['result']['data'][:5]:  # å‰5å¤§å–å‡º
                    sell_list.append({
                        'type': 'å–å‡º',
                        'name': item.get('OPERATEDEPT_NAME', ''),
                        'buy_amount': item.get('BUY', 0) / 10000,  # ä¸‡å…ƒ
                        'sell_amount': item.get('SELL', 0) / 10000,  # ä¸‡å…ƒ
                        'net_amount': item.get('NET', 0) / 10000  # å‡€å–å‡ºï¼ˆä¸‡å…ƒï¼‰
                    })
            
            details = buy_list + sell_list
        
        except Exception as e:
            print(f"è·å–é¾™è™æ¦œæ˜ç»†å¤±è´¥: {e}")
        
        return details
    
    def format_info(self, info):
        """æ ¼å¼åŒ–ä¿¡æ¯ä¸ºè¯¦ç»†æ–‡æœ¬"""
        text = f"è‚¡ç¥¨ä»£ç ï¼š{info['code']}\n"
        text += f"è·å–æ—¶é—´ï¼š{info['timestamp']}\n\n"
        
        # å…¬å¸ä¿¡æ¯
        if info.get('company_info'):
            text += "=" * 60 + "\n"
            text += "ğŸ¢ å…¬å¸ä¿¡æ¯\n"
            text += "=" * 60 + "\n"
            company = info['company_info']
            if company.get('name'):
                text += f"å…¬å¸åç§°ï¼š{company['name']}\n"
            if company.get('industry'):
                text += f"æ‰€å±è¡Œä¸šï¼š{company['industry']}\n"
            if company.get('main_business'):
                text += f"ä¸»è¥ä¸šåŠ¡ï¼š{company['main_business']}\n"
            if company.get('listing_date'):
                text += f"ä¸Šå¸‚æ—¥æœŸï¼š{company['listing_date']}\n"
            if company.get('turnover_rate'):
                text += f"æ¢æ‰‹ç‡ï¼š{company['turnover_rate']:.2f}%\n"
            text += "\n"
        
        # è´¢åŠ¡æ•°æ®ï¼ˆå¢å¼ºç‰ˆï¼‰
        if info.get('financial'):
            text += "=" * 60 + "\n"
            text += "ğŸ’° è´¢åŠ¡æ•°æ®\n"
            text += "=" * 60 + "\n"
            fin = info['financial']
            if fin.get('total_market_cap'):
                text += f"æ€»å¸‚å€¼ï¼š{fin['total_market_cap']:.2f}äº¿å…ƒ\n"
            if fin.get('circulation_market_cap'):
                text += f"æµé€šå¸‚å€¼ï¼š{fin['circulation_market_cap']:.2f}äº¿å…ƒ\n"
            if fin.get('pe_ratio'):
                text += f"å¸‚ç›ˆç‡(PE)ï¼š{fin['pe_ratio']:.2f}\n"
            if fin.get('pb_ratio'):
                text += f"å¸‚å‡€ç‡(PB)ï¼š{fin['pb_ratio']:.2f}\n"
            if fin.get('ps_ratio'):
                text += f"å¸‚é”€ç‡(PS)ï¼š{fin['ps_ratio']:.2f}\n"
            if fin.get('pcf_ratio'):
                text += f"å¸‚ç°ç‡(PCF)ï¼š{fin['pcf_ratio']:.2f}\n"
            if fin.get('roe'):
                text += f"å‡€èµ„äº§æ”¶ç›Šç‡(ROE)ï¼š{fin['roe']:.2f}%\n"
            if fin.get('eps'):
                text += f"æ¯è‚¡æ”¶ç›Š(EPS)ï¼š{fin['eps']:.2f}å…ƒ\n"
            if fin.get('bvps'):
                text += f"æ¯è‚¡å‡€èµ„äº§(BVPS)ï¼š{fin['bvps']:.2f}å…ƒ\n"
            text += "\n"
        
        # èµ„é‡‘æµå‘
        if info.get('capital_flow'):
            text += "=" * 60 + "\n"
            text += "ğŸ’¸ èµ„é‡‘æµå‘ï¼ˆä»Šæ—¥ï¼‰\n"
            text += "=" * 60 + "\n"
            flow = info['capital_flow']
            if flow.get('main_net_inflow') is not None:
                text += f"ä¸»åŠ›å‡€æµå…¥ï¼š{flow['main_net_inflow']:.2f}ä¸‡å…ƒ\n"
            if flow.get('super_net_inflow') is not None:
                text += f"è¶…å¤§å•å‡€æµå…¥ï¼š{flow['super_net_inflow']:.2f}ä¸‡å…ƒ\n"
            if flow.get('large_net_inflow') is not None:
                text += f"å¤§å•å‡€æµå…¥ï¼š{flow['large_net_inflow']:.2f}ä¸‡å…ƒ\n"
            if flow.get('medium_net_inflow') is not None:
                text += f"ä¸­å•å‡€æµå…¥ï¼š{flow['medium_net_inflow']:.2f}ä¸‡å…ƒ\n"
            if flow.get('small_net_inflow') is not None:
                text += f"å°å•å‡€æµå…¥ï¼š{flow['small_net_inflow']:.2f}ä¸‡å…ƒ\n"
            text += "\n"
        
        # è‚¡ä¸œä¿¡æ¯
        if info.get('holder_info'):
            text += "=" * 60 + "\n"
            text += "ğŸ‘¥ è‚¡ä¸œä¿¡æ¯\n"
            text += "=" * 60 + "\n"
            holder = info['holder_info']
            if holder.get('holder_count'):
                text += f"è‚¡ä¸œæˆ·æ•°ï¼š{holder['holder_count']}\n"
            if holder.get('avg_hold'):
                text += f"äººå‡æŒè‚¡ï¼š{holder['avg_hold']}è‚¡\n"
            if holder.get('top10_ratio'):
                text += f"å‰åå¤§è‚¡ä¸œæŒè‚¡æ¯”ä¾‹ï¼š{holder['top10_ratio']:.2f}%\n"
            text += "\n"
        
        # ç ”æŠ¥
        if info.get('research_reports'):
            text += "=" * 60 + "\n"
            text += "ğŸ“Š ç ”ç©¶æŠ¥å‘Š\n"
            text += "=" * 60 + "\n"
            if info['research_reports']:
                for i, report in enumerate(info['research_reports'], 1):
                    text += f"\n{i}. {report['title']}\n"
                    text += f"   æœºæ„ï¼š{report['org']}\n"
                    text += f"   ç ”ç©¶å‘˜ï¼š{report['researcher']}\n"
                    text += f"   è¯„çº§ï¼š{report['rating']}\n"
                    text += f"   æ—¥æœŸï¼š{report['date']}\n"
            else:
                text += "æš‚æ— ç ”æŠ¥ä¿¡æ¯\n"
            text += "\n"
        
        # å…¬å‘Š
        text += "=" * 60 + "\n"
        text += "ğŸ“¢ å…¬å‘Šä¿¡æ¯ï¼ˆè¿‘1ä¸ªæœˆï¼Œæœ€è¿‘5æ¡ï¼‰\n"
        text += "=" * 60 + "\n"
        if info['announcements']:
            # ç»Ÿè®¡å…¬å‘Šæ•°é‡
            real_announcements = [ann for ann in info['announcements'] if ann.get('type') != 'ç³»ç»Ÿæç¤º']
            if real_announcements:
                text += f"å…±è·å–åˆ° {len(real_announcements)} æ¡å…¬å‘Š\n\n"
                for i, ann in enumerate(real_announcements[:5], 1):  # åªæ˜¾ç¤ºå‰5æ¡
                    text += f"{i}. {ann['title']}\n"
                    text += f"   æ—¥æœŸï¼š{ann['date']}\n"
                    text += f"   ç±»å‹ï¼š{ann['type']}\n"
                    text += f"   æ‘˜è¦ï¼š{ann['summary']}\n\n"
                
                if len(real_announcements) > 5:
                    text += f"...è¿˜æœ‰ {len(real_announcements) - 5} æ¡å…¬å‘Šæœªæ˜¾ç¤º\n"
            else:
                # æ˜¾ç¤ºç³»ç»Ÿæç¤º
                for ann in info['announcements']:
                    text += f"{ann['summary']}\n"
        else:
            text += "æš‚æ— å…¬å‘Šä¿¡æ¯\n"
        
        # æ–°é—»
        text += "\n" + "=" * 60 + "\n"
        text += "ğŸ“° æ–°é—»èµ„è®¯\n"
        text += "=" * 60 + "\n"
        if info['news']:
            for i, news in enumerate(info['news'][:10], 1):  # æ˜¾ç¤ºå‰10æ¡
                text += f"\n{i}. {news['title']}\n"
                text += f"   æ—¥æœŸï¼š{news['date']}\n"
                text += f"   æ¥æºï¼š{news['source']}\n"
                if news.get('summary'):
                    text += f"   æ‘˜è¦ï¼š{news['summary']}\n"
        else:
            text += "æš‚æ— æ–°é—»èµ„è®¯\n"
        
        # é¾™è™æ¦œ
        if info.get('dragon_tiger'):
            text += "\n" + "=" * 60 + "\n"
            text += "ğŸ‰ é¾™è™æ¦œæ•°æ®ï¼ˆè¿‘1ä¸ªæœˆï¼Œæœ€è¿‘3æ¬¡ï¼‰\n"
            text += "=" * 60 + "\n"
            
            dragon_tiger = info['dragon_tiger']
            real_records = [rec for rec in dragon_tiger if not rec.get('note')]
            
            if real_records:
                text += f"å…±ä¸Šæ¦œ {len(real_records)} æ¬¡\n\n"
                
                for i, record in enumerate(real_records, 1):
                    text += f"â”Œâ”€ ç¬¬{i}æ¬¡ä¸Šæ¦œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n"
                    text += f"â”‚ æ—¥æœŸï¼š{record['date']}\n"
                    text += f"â”‚ ä¸Šæ¦œåŸå› ï¼š{record['reason']}\n"
                    text += f"â”‚ æ”¶ç›˜ä»·ï¼š{record['close_price']:.2f}å…ƒ\n"
                    text += f"â”‚ æ¶¨è·Œå¹…ï¼š{record['change_pct']:+.2f}%\n"
                    text += f"â”‚ æˆäº¤é¢ï¼š{record['turnover']:.2f}äº¿å…ƒ\n"
                    text += f"â”‚ é¾™è™æ¦œå‡€ä¹°å…¥ï¼š{record['net_amount']:+.2f}ä¸‡å…ƒ\n"
                    text += f"â”‚ é¾™è™æ¦œä¹°å…¥é¢ï¼š{record['buy_amount']:.2f}ä¸‡å…ƒ\n"
                    text += f"â”‚ é¾™è™æ¦œå–å‡ºé¢ï¼š{record['sell_amount']:.2f}ä¸‡å…ƒ\n"
                    text += f"â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
                    
                    # è¥ä¸šéƒ¨æ˜ç»†
                    if record.get('details'):
                        # ä¹°å…¥è¥ä¸šéƒ¨
                        buy_details = [d for d in record['details'] if d['type'] == 'ä¹°å…¥']
                        if buy_details:
                            text += "\n  â”Œâ”€ ä¹°å…¥å‰5å¤§è¥ä¸šéƒ¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n"
                            for j, detail in enumerate(buy_details, 1):
                                text += f"  â”‚ {j}. {detail['name']}\n"
                                text += f"  â”‚    ä¹°å…¥ï¼š{detail['buy_amount']:>10.2f}ä¸‡å…ƒ\n"
                                text += f"  â”‚    å–å‡ºï¼š{detail['sell_amount']:>10.2f}ä¸‡å…ƒ\n"
                                text += f"  â”‚    å‡€é¢ï¼š{detail['net_amount']:>+10.2f}ä¸‡å…ƒ\n"
                                if j < len(buy_details):
                                    text += f"  â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                            text += f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
                        
                        # å–å‡ºè¥ä¸šéƒ¨
                        sell_details = [d for d in record['details'] if d['type'] == 'å–å‡º']
                        if sell_details:
                            text += "\n  â”Œâ”€ å–å‡ºå‰5å¤§è¥ä¸šéƒ¨ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n"
                            for j, detail in enumerate(sell_details, 1):
                                text += f"  â”‚ {j}. {detail['name']}\n"
                                text += f"  â”‚    ä¹°å…¥ï¼š{detail['buy_amount']:>10.2f}ä¸‡å…ƒ\n"
                                text += f"  â”‚    å–å‡ºï¼š{detail['sell_amount']:>10.2f}ä¸‡å…ƒ\n"
                                text += f"  â”‚    å‡€é¢ï¼š{detail['net_amount']:>+10.2f}ä¸‡å…ƒ\n"
                                if j < len(sell_details):
                                    text += f"  â”‚    â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
                            text += f"  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
                    
                    text += "\n"
            else:
                # æ˜¾ç¤ºæœªä¸Šæ¦œè¯´æ˜
                for record in dragon_tiger:
                    if record.get('note'):
                        text += f"{record['note']}\n"
        
        return text


if __name__ == '__main__':
    # æµ‹è¯•
    crawler = StockInfoCrawler()
    
    print("æµ‹è¯•è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯...")
    info = crawler.get_stock_info('600519')
    
    print(crawler.format_info(info))
